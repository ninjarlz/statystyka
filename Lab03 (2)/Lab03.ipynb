{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 3 - algorytm Najbliższej Średniej (NM)\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest implementacja klasyfikatora najbliższej średniej NM (*Nearest Mean*).\n",
    "\n",
    "### Zbiór danych\n",
    "\n",
    "Zbiór danych znajduje się w `dataset/leaf.csv`. Jest to zbiór danych pobrany z adresu: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyłanie zadań\n",
    "\n",
    "Wszystkie pliki należy spakować archiwizatorem **zip** i przesłać za pośrednictwem platformy WIKAMP. Poniżej oczekiwana zawartość archiwum:\n",
    "\n",
    "```\n",
    "+-- 📂 [IMIE I NAZWISKO].zip\n",
    "    +-- 📜 Lab03.ipynb\n",
    "    +-- 📂 dataset\n",
    "        +-- 📜 leaf.csv\n",
    "        +-- 📜 ReadMe.pdf\n",
    "```\n",
    "\n",
    "*UWAGA: Wysyłając zadanie potwierdasz, że wykonałeś je samodzielnie i jest to Twoja indywidualna praca i materiał przedstawiony w tej pracy jest dla Ciebie zrozumiały.*\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Należy wykonać następujące czynności w celu realizacji niniejszego zadania:\n",
    "* Wczytaj dane.\n",
    "* Rozszerz zbiór danych.\n",
    "* Podziel dane na zbiór treningowy i testowy.\n",
    "* Zaimplementuj funkcję, która zwraca macierz kowariancji (*uwaga: biblioteka `numpy` posiada gotową implementację `cov` z którą możesz porównać wynik*).\n",
    "* **Zaimplementuj klasyfikator najbliższej średniej (NM) z zastosowaniem odległości Euklidesa**.\n",
    "* **Zaimplementuj klasyfikator najbliższej średniej (NM) z zastosowaniem odległości Machalanobisa**.\n",
    "* Opisz wyniki klasyfikatorów i porównaj je z klasyfikatorem *k*NN (porównaj w kontekście różnych metryk - obowiązkowo tablica pomyłek).\n",
    "\n",
    "> Podpowiedź 1: Do obliczenia macierzy odwrotnej możesz użyć gotową implementację, np. funkcję `linalg.inv` z biblioteki `numpy`.\n",
    "\n",
    "> Podpowiedź 2: Do wszelkich podstawowych operacji na macierzach (mnożenie, transpozycja, dodawanie, odejmowanie, itp.) możesz zastosować gotową implementację, np. bibliotekę `numpy`.\n",
    "\n",
    "> UWAGA 1: W niniejszym zadaniu jest dowolność implementacji (nie trzeba trzymać się struktury z poprzedniego zadania), jednak algorytm NM należy zaimplementować samodzielnie bez korzystania z istniających rozwiązań (jak np. z biblioteki `scikit-learn`).\n",
    "\n",
    "> UWAGA 2: Wszystkie wykonane elementy zadania powinny posiadać stosowne komentarze i opisy.\n",
    "\n",
    "\n",
    "<span style=\"text-decoration:underline\">Referencje</span>\n",
    "\n",
    "1. Mahalanobis, P C, _On test and measures of group divergence : theoretical formulae_, Journal and Proceedings of Asiatic Society of Bengal (New Series) Vol. 26, pp. 541-588. 1930. (URL: http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/1639/029.pdf)\n",
    "2. McLachlan, Goeffrey J. _Mahalanobis distance_, Resonance, pp. 20-26. 1999. (URL: https://www.ias.ac.in/article/fulltext/reso/004/06/0020-0026)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PONIŻEJ WYKONAJ ZADANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 classes, features {4, 12, 15}, k 3\n",
      "kNN:\n",
      "Accuracy is: 0.8\n",
      "Balanced accuracy is: 0.8\n",
      "Confusion matrix: \n",
      "[[1 0 0 1 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 1 0 1]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 2]]\n",
      "NM euclides:\n",
      "Accuracy is: 0.5\n",
      "Balanced accuracy is: 0.5\n",
      "Confusion matrix: \n",
      "[[0 1 1 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 0 0 2]]\n",
      "NM mahalanobis:\n",
      "Accuracy is: 0.9\n",
      "Balanced accuracy is: 0.9\n",
      "Confusion matrix: \n",
      "[[2 0 0 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 2]]\n",
      "-----------------------------------------\n",
      "12 classes, features {4, 5, 6, 12, 15}, k 3\n",
      "kNN:\n",
      "Accuracy is: 0.5555555555555556\n",
      "Balanced accuracy is: 0.5555555555555555\n",
      "Confusion matrix: \n",
      "[[1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0]]\n",
      "NM euclides:\n",
      "Accuracy is: 0.5925925925925926\n",
      "Balanced accuracy is: 0.5972222222222222\n",
      "Confusion matrix: \n",
      "[[1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 2 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0]]\n",
      "NM mahalanobis:\n",
      "Accuracy is: 0.8518518518518519\n",
      "Balanced accuracy is: 0.8333333333333334\n",
      "Confusion matrix: \n",
      "[[1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "with open('./dataset/leaf.csv', 'rb') as f:\n",
    "    data = np.genfromtxt(f, delimiter=',')\n",
    "\n",
    "five_classes = [3., 5., 6., 7., 8.]\n",
    "twelve_classes = [3., 5., 6., 7., 8., 10. , 11., 12., 13., 14., 15., 30.]\n",
    "\n",
    "def prepare_data_sets(classes):\n",
    "    test = None\n",
    "    train = None\n",
    "    for c in classes:\n",
    "        filtered = data[(data[:, 0] == c)]\n",
    "        test_len = round(0.2 * len(filtered))\n",
    "        train_len = len(filtered) - test_len\n",
    "        test_c = filtered[:test_len, :]\n",
    "        train_c = filtered[-train_len:, :]\n",
    "        if test is None:\n",
    "            test = test_c\n",
    "        else:\n",
    "            test = np.concatenate((test, test_c))\n",
    "        if train is None:\n",
    "            train = train_c\n",
    "        else:\n",
    "            train = np.concatenate((train, train_c))\n",
    "    return train, test\n",
    "\n",
    "train_five_classes, test_five_classes =  prepare_data_sets(five_classes)\n",
    "train_twelve_classes, test_twelve_classes = prepare_data_sets(twelve_classes)\n",
    "\n",
    "class TestSample:\n",
    "\n",
    "    classified_as = None\n",
    "    original_classification = None\n",
    "\n",
    "    def __init__(self, original_classification, classified_as):\n",
    "        self.original_classification = original_classification\n",
    "        self.classified_as = classified_as\n",
    "\n",
    "    def is_properly_classified(self):\n",
    "        return self.original_classification == self.classified_as\n",
    "\n",
    "class Neighbour:\n",
    "\n",
    "    distance = None\n",
    "    class_value = None\n",
    "\n",
    "    def __init__(self, class_value, distance):\n",
    "        self.class_value = class_value\n",
    "        self.distance = distance\n",
    "\n",
    "def mahalanobis_dist(sample_vector, mean_vector, inverted_cov_matrix):\n",
    "    subtracted = np.subtract(sample_vector, mean_vector)\n",
    "    subtracted_transposed = np.transpose(subtracted)\n",
    "    matrix = np.matmul(subtracted_transposed, inverted_cov_matrix)\n",
    "    return np.vdot(matrix, subtracted)\n",
    "\n",
    "def euclidian_dist(sample1, sample2, features_list):\n",
    "    value = 0\n",
    "    for feature in features_list:\n",
    "        value += (sample1[feature] - sample2[feature]) ** 2\n",
    "    return math.sqrt(value)\n",
    "\n",
    "def get_class_from_nearest_neighbours(nearest_neighbours):\n",
    "    nearest_neighbours_dict = {}\n",
    "    for nearest_neighbour in nearest_neighbours:\n",
    "        if nearest_neighbour.class_value in nearest_neighbours_dict:\n",
    "            nearest_neighbours_dict[nearest_neighbour.class_value].append(nearest_neighbour)\n",
    "        else:\n",
    "            nearest_neighbours_dict[nearest_neighbour.class_value] = [nearest_neighbour]\n",
    "    max_size = 0\n",
    "    class_value = None\n",
    "    for k in nearest_neighbours_dict.keys():\n",
    "        size = len(nearest_neighbours_dict[k])\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            class_value = k\n",
    "    return class_value\n",
    "\n",
    "def get_covariant_matrix(class_samples, mean_vector,  features_list):\n",
    "    class_vectors = []\n",
    "    for train_sample in class_samples:\n",
    "        train_sample_vector = get_vector_from_sample(train_sample, features_list)\n",
    "        class_vectors.append(train_sample_vector)\n",
    "    mean_vector_len = len(class_vectors)\n",
    "    class_vectors = np.transpose(np.asarray(class_vectors))\n",
    "    mean_vectors = []\n",
    "    for i in range(mean_vector_len):\n",
    "        mean_vectors.append(mean_vector)\n",
    "    mean_vectors = np.transpose(np.asarray(mean_vectors))\n",
    "    subtracted = np.subtract(class_vectors, mean_vectors)\n",
    "    transposed_subtracted = np.transpose(subtracted)\n",
    "    return (1 / len(class_vectors)) * np.matmul(subtracted, transposed_subtracted)\n",
    "\n",
    "def get_mean_vector(filtered, features_list):\n",
    "    mean = []\n",
    "    for i in range(len(features_list)):\n",
    "        mean.append(0.)\n",
    "    for sample in filtered:\n",
    "        sample_vector = get_vector_from_sample(sample, features_list)\n",
    "        for i in range(len(sample_vector)):\n",
    "            mean[i] += sample_vector[i]\n",
    "    for i in range(len(features_list)):\n",
    "        mean[i] /= len(filtered)\n",
    "    return np.asarray(mean)\n",
    "\n",
    "def get_vector_from_sample(sample, features_list):\n",
    "    vector = []\n",
    "    for feature in features_list:\n",
    "        vector.append(sample[feature])\n",
    "    return np.asarray(vector)\n",
    "\n",
    "def get_mean_value(filtered, features_list):\n",
    "    mean = []\n",
    "    for i in range(16):\n",
    "        mean.append(0.)\n",
    "    for feature in features_list:\n",
    "        for sample in filtered:\n",
    "            mean[feature] += sample[feature]\n",
    "        mean[feature] /= len(filtered)\n",
    "    return np.asarray(mean)\n",
    "\n",
    "def get_mean_values(train_set, classes, features_list):\n",
    "    mean_values = {}\n",
    "    for c in classes:\n",
    "        filtered = train_set[(train_set[:, 0] == c)]\n",
    "        mean_values[c] = get_mean_value(filtered, features_list)\n",
    "    return mean_values\n",
    "\n",
    "classified_samples = []\n",
    "def classify_knn_samples(test_set, train_set, k, features_list):\n",
    "    classified_samples.clear()\n",
    "    for test_sample in test_set:\n",
    "        neighbours = []\n",
    "        for train_sample in train_set:\n",
    "            dist = euclidian_dist(test_sample, train_sample, features_list)\n",
    "            neighbours.append(Neighbour(train_sample[0], dist))\n",
    "        neighbours.sort(key=lambda x: x.distance, reverse=False)\n",
    "        nearest_neighbours = neighbours[:k]\n",
    "        classified_class = get_class_from_nearest_neighbours(nearest_neighbours)\n",
    "        classified_samples.append(TestSample(test_sample[0], classified_class))\n",
    "\n",
    "def classify_nm_euclides_samples(test_set, train_set, classes, features_list):\n",
    "    classified_samples.clear()\n",
    "    mean_values = get_mean_values(train_set, classes, features_list)\n",
    "    for test_sample in test_set:\n",
    "        min_dist = None\n",
    "        classified_class = None\n",
    "        for c in mean_values.keys():\n",
    "            dist = euclidian_dist(test_sample, mean_values[c], features_list)\n",
    "            if min_dist is None or dist < min_dist:\n",
    "                min_dist = dist\n",
    "                classified_class = c\n",
    "        classified_samples.append(TestSample(test_sample[0], classified_class))\n",
    "\n",
    "def classify_nm_mahalanobis_samples(test_set, train_set, classes, features_list):\n",
    "    classified_samples.clear()\n",
    "    inv_cov_matrices = {}\n",
    "    mean_vectors = {}\n",
    "    for c in classes:\n",
    "        class_samples = train_set[(train_set[:, 0] == c)]\n",
    "        mean_vector = get_mean_vector(class_samples, features_list)\n",
    "        mean_vectors[c] = mean_vector\n",
    "        cov = get_covariant_matrix(class_samples, mean_vector, features_list)\n",
    "        inv_cov_matrices[c] = np.linalg.inv(cov)\n",
    "    for test_sample in test_set:\n",
    "        test_sample_vector = get_vector_from_sample(test_sample, features_list)\n",
    "        min_dist = None\n",
    "        classified_class = None\n",
    "        for c in inv_cov_matrices.keys():\n",
    "            dist = mahalanobis_dist(test_sample_vector, mean_vectors[c], inv_cov_matrices[c])\n",
    "            if min_dist is None or dist < min_dist:\n",
    "                min_dist = dist\n",
    "                classified_class = c\n",
    "        classified_samples.append(TestSample(test_sample[0], classified_class))\n",
    "\n",
    "\n",
    "def print_accuracy():\n",
    "    properly_classified_samples = 0\n",
    "    for classified_sample in classified_samples:\n",
    "        if classified_sample.is_properly_classified():\n",
    "            properly_classified_samples += 1\n",
    "    print(\"Accuracy is: \" + str(properly_classified_samples / len(classified_samples)))\n",
    "\n",
    "def fill_classification_data(classified, class_true, class_pred):\n",
    "    for sample in classified:\n",
    "        class_true.append(sample.original_classification)\n",
    "        class_pred.append(sample.classified_as)\n",
    "\n",
    "def print_confusion_matrix(classified):\n",
    "    class_true = []\n",
    "    class_pred = []\n",
    "    fill_classification_data(classified, class_true, class_pred)\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(confusion_matrix(class_true, class_pred))\n",
    "\n",
    "def print_balanced_accuracy(classified):\n",
    "    class_true = []\n",
    "    class_pred = []\n",
    "    fill_classification_data(classified, class_true, class_pred)\n",
    "    print(\"Balanced accuracy is: \" + str(balanced_accuracy_score(class_true, class_pred)))\n",
    "\n",
    "def print_classification_parameters(classified):\n",
    "    print_accuracy()\n",
    "    print_balanced_accuracy(classified)\n",
    "    print_confusion_matrix(classified)\n",
    "\n",
    "print(\"5 classes, features {4, 12, 15}, k 3\")\n",
    "features = [4, 12, 15]\n",
    "classify_knn_samples(test_five_classes, train_five_classes, 3, features)\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nm_euclides_samples(test_five_classes, train_five_classes, five_classes, features)\n",
    "print(\"NM euclides:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nm_mahalanobis_samples(test_five_classes, train_five_classes, five_classes, features)\n",
    "print(\"NM mahalanobis:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "# Results:\n",
    "# For classes {3, 5, 6, 7, 8} features {4, 12, 15} and k equals to 3 we\n",
    "# have the following results:\n",
    "#\n",
    "# 1. kNN:\n",
    "#   Accuracy is: 0.8\n",
    "#   Balanced accuracy is: 0.8\n",
    "# 2. NM euclides:\n",
    "#   Accuracy is: 0.5\n",
    "#   Balanced accuracy is: 0.5\n",
    "# 3. NM mahalanobis:\n",
    "#   Accuracy is: 0.9\n",
    "#   Balanced accuracy is: 0.9\n",
    "#\n",
    "#  As one can see, the 'NM mahalanobis' method has the best results comparing to 'kNN' and 'NM euclides' ones\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print(\"12 classes, features {4, 5, 6, 12, 15}, k 3\")\n",
    "features = [4, 5, 6, 12, 15]\n",
    "classify_knn_samples(test_twelve_classes, train_twelve_classes, 3, features)\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nm_euclides_samples(test_twelve_classes, train_twelve_classes, twelve_classes, features)\n",
    "print(\"NM euclides:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nm_mahalanobis_samples(test_twelve_classes, train_twelve_classes, twelve_classes, features)\n",
    "print(\"NM mahalanobis:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "# Results:\n",
    "# For classes {3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 30} features {4, 5, 6, 12, 15} and k equals to 3 we\n",
    "# have the following results:\n",
    "#\n",
    "# 1. kNN:\n",
    "#   Accuracy is: 0.5555555555555556\n",
    "#   Balanced accuracy is: 0.5555555555555555\n",
    "# 2. NM euclides:\n",
    "#   Accuracy is: 0.5925925925925926\n",
    "#   Balanced accuracy is: 0.5972222222222222\n",
    "# 3. NM mahalanobis:\n",
    "#   Accuracy is: 0.8518518518518519\n",
    "#   Balanced accuracy is: 0.8333333333333334\n",
    "#\n",
    "#  As one can see, the 'NM mahalanobis' method has again the best results comparing to 'kNN' and 'NM euclides' ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "0 2 0 0 0 0 0]\n",
    " [0 0 0 0 0 0 0 1 0 0 0 1]\n",
    " [0 0 0 0 0 0 0 0 3 0 0 0]\n",
    " [0 0 0 0 0 0 0"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}