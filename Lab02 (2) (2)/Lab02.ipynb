{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 2 - algorytm *k* Najbliższych Sąsiadów (*k*NN)\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest implementacja klasyfikatora *k* najbliższych sąsiadów - *k*NN (*k Nearest Neighbors*) oraz zapoznanie się z innymi metrykami klasyfikacji.\n",
    "\n",
    "### Termin\n",
    "Zadanie należy wykonać tego samego dnia. \n",
    "\n",
    "### System oceniania\n",
    "\n",
    "| Liczba punktów (procentowo) | Ocena |\n",
    "| :----                    | ---: |\n",
    "| [0-50)   | 2   |\n",
    "| [50-60)  | 3   |\n",
    "| [60-70)  | 3.5 |\n",
    "| [70-80)  | 4   |\n",
    "| [80-90)  | 4.5 |\n",
    "| [90-100] | 5   |\n",
    "\n",
    "<u>Punkty ujemne</u>\n",
    "\n",
    "* `ocena - 0.5` jeżeli zadanie wysłano po laboratorium, ale < 7 dni; \n",
    "* `ocena - 1` jeżeli zadanie wysłano w terminie pomiędzy 7 a 14 dni;\n",
    "* `ocena - 1.5` jeżeli zadanie wysłano po upływie 14 dni, ale przed ostatnim laboratorium;\n",
    "* `ocena = 2` jeżeli zadanie wysłano po ostatnim laboratorium.\n",
    "\n",
    "<u>Uwaga:</u>\n",
    "\n",
    "Niedopuszczalne jest dzielenie się notatnikiem (plik `.ipynb`) z innymi studentami ani udostępnianie go w Internecie. Każdy student powinien pobrać notatnik samodzielnie z platformy WIKAMP.\n",
    "Wysyłając zadanie potwierdasz, że wykonałeś je samodzielnie i jest to Twoja indywidualna praca a materiał przedstawiony w tej pracy jest dla Ciebie zrozumiały. Prace bardzo podobne albo grupowe będą uznawane za plagiat.\n",
    "\n",
    "\n",
    "### Zbiór danych\n",
    "\n",
    "Zbiór danych znajduje się w katalogu `dataset/*`. Jest to zmodyfikowany zbiór danych znajdujący się pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyłanie zadań\n",
    "\n",
    "Wszystkie pliki należy spakować archiwizatorem **zip** i przesłać za pośrednictwem platformy WIKAMP. Poniżej oczekiwana zawartość archiwum:\n",
    "\n",
    "```\n",
    "+-- 📂 [IMIE.NAZWISKO].zip\n",
    "    +-- 📜 Lab02.ipynb\n",
    "    +-- 📂 dataset\n",
    "        +-- 📜 dataset.npz\n",
    "        +-- 📜 ReadMe.pdf\n",
    "```\n",
    "\n",
    "### Dodatkowe narzędzia\n",
    "\n",
    "Dopuszczalne jest korzystanie z bibliotek: `numpy`, `pandas`, `matplotlib`.\n",
    "Implementacja klasyfikatora powinna być wykonana samodzielnie (bez dodatkowych bibliotek).\n",
    "\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Należy wykonać następujące czynności w celu realizacji niniejszego zadania:\n",
    "* Wczytaj dane.\n",
    "* **Zaimplementuj klasyfikator *k* najbliższych sąsiadów (*k*NN)** i uruchom predykcję.\n",
    "* Opisz jak zmieniają się wyniki klasyfikatora dla różnych wartości *k*, dla różnej liczby klas oraz dla różnej liczby cech.\n",
    "* Wyświetl tablicę pomyłek (*confusion matrix*). W tym przypadku możesz zastosować gotową implementację z biblioteki `scikit-learn` <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html>.\n",
    "* Odszukaj przynajmniej dwie inne (niż accuracy) metryki przytatne w klasyfikacji na stronie <https://scikit-learn.org/stable/modules/model_evaluation.html> i opisz ich wyniki. Wytłumacz czym się różnią i co można z nich odczytać.\n",
    "* Opisz różnicę wyników klasyfikacji obu algorytmów (NN i *k*NN)?\n",
    "\n",
    "\n",
    "> UWAGA: Wszystkie wykonane elementy zadania powinny posiadać stosowne komentarze i opisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PONIŻEJ WYKONAJ ZADANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {3, 5}, features {5, 15}, k 3\n",
      "kNN:\n",
      "Accuracy is: 0.7363636363636363\n",
      "Balanced accuracy is: 0.7363636363636363\n",
      "Precision score (macro='weighted') is: 0.7364417989417988\n",
      "Confusion matrix: \n",
      "[[41 14]\n",
      " [15 40]]\n",
      "NN:\n",
      "Accuracy is: 0.7\n",
      "Balanced accuracy is: 0.7\n",
      "Precision score (macro='weighted') is: 0.7016666666666667\n",
      "Confusion matrix: \n",
      "[[41 14]\n",
      " [19 36]]\n",
      "-----------------------------------------\n",
      "Classes: {3, 5}, features {5, 15}, k 21\n",
      "kNN:\n",
      "Accuracy is: 0.7818181818181819\n",
      "Balanced accuracy is: 0.7818181818181819\n",
      "Precision score (macro='weighted') is: 0.7833167165171152\n",
      "Confusion matrix: \n",
      "[[45 10]\n",
      " [14 41]]\n",
      "NN:\n",
      "Accuracy is: 0.7\n",
      "Balanced accuracy is: 0.7\n",
      "Precision score (macro='weighted') is: 0.7016666666666667\n",
      "Confusion matrix: \n",
      "[[41 14]\n",
      " [19 36]]\n",
      "-----------------------------------------\n",
      "Classes: {3, 5, 6, 7, 8}, features {5, 15}, k 3\n",
      "kNN:\n",
      "Accuracy is: 0.42207792207792205\n",
      "Balanced accuracy is: 0.43969696969696964\n",
      "Precision score (macro='weighted') is: 0.4118908580404707\n",
      "Confusion matrix: \n",
      "[[19  6  9  7 14]\n",
      " [ 3 24  4 22  2]\n",
      " [ 3  4 35  1  1]\n",
      " [14 16 16  8 12]\n",
      " [22  5  7 10 44]]\n",
      "NN:\n",
      "Accuracy is: 0.37987012987012986\n",
      "Balanced accuracy is: 0.39636363636363636\n",
      "Precision score (macro='weighted') is: 0.37953006500541714\n",
      "Confusion matrix: \n",
      "[[15  6  7 10 17]\n",
      " [ 9 19  4 21  2]\n",
      " [ 3  5 34  1  1]\n",
      " [17 16 13  9 11]\n",
      " [27  4  6 11 40]]\n",
      "-----------------------------------------\n",
      "Classes: {3, 5, 6, 7, 8}, features {5, 15, 6, 7, 8}, k 3\n",
      "kNN:\n",
      "Accuracy is: 0.7077922077922078\n",
      "Balanced accuracy is: 0.7127272727272727\n",
      "Precision score (macro='weighted') is: 0.7049078552311311\n",
      "Confusion matrix: \n",
      "[[43  0  0 12  0]\n",
      " [ 0 48  1  3  3]\n",
      " [ 0  8 35  0  1]\n",
      " [36  2  1 18  9]\n",
      " [ 1  7  0  6 74]]\n",
      "NN:\n",
      "Accuracy is: 0.6915584415584416\n",
      "Balanced accuracy is: 0.6922727272727274\n",
      "Precision score (macro='weighted') is: 0.6889985245466973\n",
      "Confusion matrix: \n",
      "[[42  0  0 13  0]\n",
      " [ 0 44  1  7  3]\n",
      " [ 0  9 34  0  1]\n",
      " [35  3  1 18  9]\n",
      " [ 1  7  0  5 75]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    train, test = data['train'], data['test']\n",
    "\n",
    "train_two_classes = train[((train[:,0] == 3) | (train[:,0] == 5))]\n",
    "test_two_classes = test[((test[:,0] == 3) | (test[:,0] == 5))]\n",
    "\n",
    "train_five_classes = train[((train[:,0] == 3) | (train[:,0] == 5) | (train[:,0] == 6) | (train[:,0] == 7) | (train[:,0] == 8))]\n",
    "test_five_classes = test[((test[:,0] == 3) | (test[:,0] == 5) | (test[:,0] == 6) | (test[:,0] == 7) | (test[:,0] == 8))]\n",
    "\n",
    "\n",
    "class TestSample:\n",
    "\n",
    "    classified_as = None\n",
    "    value = None\n",
    "\n",
    "    def __init__(self, value, classified_as):\n",
    "        self.value = value\n",
    "        self.classified_as = classified_as\n",
    "\n",
    "    def is_properly_classified(self):\n",
    "        return self.value[0] == self.classified_as\n",
    "\n",
    "class Neighbour:\n",
    "\n",
    "    distance = None\n",
    "    class_value = None\n",
    "\n",
    "    def __init__(self, class_value, distance):\n",
    "        self.class_value = class_value\n",
    "        self.distance = distance\n",
    "\n",
    "def euclidian_dist(sample1, sample2, features_list):\n",
    "    value = 0\n",
    "    for feature in features_list:\n",
    "        value += (sample1[feature] - sample2[feature]) ** 2\n",
    "    return math.sqrt(value)\n",
    "\n",
    "def get_class_from_nearest_neighbours(nearest_neighbours):\n",
    "    nearest_neighbours_dict = {}\n",
    "    for nearest_neighbour in nearest_neighbours:\n",
    "        if nearest_neighbour.class_value in nearest_neighbours_dict:\n",
    "            nearest_neighbours_dict[nearest_neighbour.class_value].append(nearest_neighbour)\n",
    "        else:\n",
    "            nearest_neighbours_dict[nearest_neighbour.class_value] = [nearest_neighbour]\n",
    "    max_size = 0\n",
    "    class_value = None\n",
    "    for k in nearest_neighbours_dict.keys():\n",
    "        size = len(nearest_neighbours_dict[k])\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            class_value = k\n",
    "    return class_value\n",
    "\n",
    "\n",
    "classified_samples = []\n",
    "def classify_knn_samples(test_set, train_set, k, features_list):\n",
    "    classified_samples.clear()\n",
    "    for test_sample in test_set:\n",
    "        neighbours = []\n",
    "        for train_sample in train_set:\n",
    "            dist = euclidian_dist(test_sample, train_sample, features_list)\n",
    "            neighbours.append(Neighbour(train_sample[0], dist))\n",
    "        neighbours.sort(key=lambda x: x.distance, reverse=False)\n",
    "        nearest_neighbours = neighbours[:k]\n",
    "        classified_class = get_class_from_nearest_neighbours(nearest_neighbours)\n",
    "        classified_samples.append(TestSample(test_sample, classified_class))\n",
    "\n",
    "def classify_nn_samples(test_set, train_set, features_list):\n",
    "    classified_samples.clear()\n",
    "    for test_sample in test_set:\n",
    "        min_dist = None\n",
    "        closest_sample = None\n",
    "        for train_sample in train_set:\n",
    "            dist = euclidian_dist(test_sample, train_sample, features_list)\n",
    "            if min_dist is None or dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_sample = train_sample\n",
    "        classified_samples.append(TestSample(test_sample, closest_sample[0]))\n",
    "\n",
    "def print_accuracy():\n",
    "    properly_classified_samples = 0\n",
    "    for classified_sample in classified_samples:\n",
    "        if classified_sample.is_properly_classified():\n",
    "            properly_classified_samples += 1\n",
    "    print(\"Accuracy is: \" + str(properly_classified_samples / len(classified_samples)))\n",
    "\n",
    "def fill_classification_data(classified, class_true, class_pred):\n",
    "    for sample in classified:\n",
    "        class_true.append(sample.value[0])\n",
    "        class_pred.append(sample.classified_as)\n",
    "\n",
    "def print_confusion_matrix(classified):\n",
    "    class_true = []\n",
    "    class_pred = []\n",
    "    fill_classification_data(classified, class_true, class_pred)\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(confusion_matrix(class_true, class_pred))\n",
    "\n",
    "def print_balanced_accuracy(classified):\n",
    "    class_true = []\n",
    "    class_pred = []\n",
    "    fill_classification_data(classified, class_true, class_pred)\n",
    "    print(\"Balanced accuracy is: \" + str(balanced_accuracy_score(class_true, class_pred)))\n",
    "\n",
    "def print_precision_score(classified):\n",
    "    class_true = []\n",
    "    class_pred = []\n",
    "    fill_classification_data(classified, class_true, class_pred)\n",
    "    print(\"Precision score (macro='weighted') is: \" + str(precision_score(class_true, class_pred, average='weighted')))\n",
    "\n",
    "def print_classification_parameters(classified):\n",
    "    print_accuracy()\n",
    "    print_balanced_accuracy(classified)\n",
    "    print_precision_score(classified)\n",
    "    print_confusion_matrix(classified)\n",
    "\n",
    "print(\"Classes: {3, 5}, features {5, 15}, k 3\")\n",
    "classify_knn_samples(test_two_classes, train_two_classes, 3, [5, 15])\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nn_samples(test_two_classes, train_two_classes, [5, 15])\n",
    "print(\"NN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "\n",
    "# Results:\n",
    "# For classes {3, 5} features {5, 15} and k equals to 3 we\n",
    "# have better accuracy for kNN than for simple NN (74% vs 70%)\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print(\"Classes: {3, 5}, features {5, 15}, k 21\")\n",
    "classify_knn_samples(test_two_classes, train_two_classes, 21, [5, 15])\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nn_samples(test_two_classes, train_two_classes, [5, 15])\n",
    "print(\"NN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "\n",
    "# Results:\n",
    "# For classes {3, 5} features {5, 15} and k equals to 21 we\n",
    "# have better accuracy for kNN than for simple NN (78% vs 70%) - for bigger k we have better kNN accuracy\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print(\"Classes: {3, 5, 6, 7, 8}, features {5, 15}, k 3\")\n",
    "classify_knn_samples(test_five_classes, train_five_classes, 3, [5, 15])\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nn_samples(test_five_classes, train_five_classes, [5, 15])\n",
    "print(\"NN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "\n",
    "# Results:\n",
    "# For classes {3, 5, 6, 7, 8} features {5, 15} and k equals to 3 we\n",
    "# have better accuracy for kNN than for simple NN (42% vs 38%) - for greater number of classes we have worse accuracy for\n",
    "# both methods\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print(\"Classes: {3, 5, 6, 7, 8}, features {5, 15, 6, 7, 8}, k 3\")\n",
    "classify_knn_samples(test_five_classes, train_five_classes, 3, [5, 15, 6, 7, 8])\n",
    "print(\"kNN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "classify_nn_samples(test_five_classes, train_five_classes, [5, 15, 6, 7, 8])\n",
    "print(\"NN:\")\n",
    "print_classification_parameters(classified_samples)\n",
    "\n",
    "# Results:\n",
    "# For classes {3, 5, 6, 7, 8} features {5, 15, 6, 7, 8} and k equals to 3 we\n",
    "# have better accuracy for kNN than for simple NN (71% vs 69%) - for greater number of features we have better accuracy for both methods"
   ]
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}